{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat = pd.read_csv('data/emb_data4.csv')\n",
    "feat = shuffle(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = feat['master_id']\n",
    "X2 = feat.drop(['master_id', 'assigne_state'], axis=1)\n",
    "X2 = scale(X2, axis=0)\n",
    "y = feat['assigne_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_masters = []\n",
    "\n",
    "for i in range(len(X1)):\n",
    "    if X1[i] not in u_masters:\n",
    "        u_masters.append(X1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113184/113184 [02:05<00:00, 902.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113184, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "X_new = pd.DataFrame(columns=['master_idx'], index = X1.index)\n",
    "for i in tqdm(range(len(X1))):\n",
    "    X_new['master_idx'][i] = u_masters.index(X1[i])\n",
    "        \n",
    "print(X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_X_new = X_new[0:20000].as_matrix()\n",
    "tst_X2 = X2[0:20000]\n",
    "tst_y = y[0:20000]\n",
    "\n",
    "val_X_new = X_new[20001:50000].as_matrix()\n",
    "val_X2 = X2[20001:50000]\n",
    "val_y = y[20001:50000]\n",
    "\n",
    "trn_X_new = X_new[50001:].as_matrix()\n",
    "trn_X2 = X2[50001:]\n",
    "trn_y = y[50001:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_X_new, val_X_new, trn_X2, val_X2, trn_y, val_y = train_test_split(X_new, X2, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, merge\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "from sklearn.metrics import roc_auc_score\n",
    "n_masters = X1.nunique()\n",
    "n_factors = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_in = Input(shape=(1,), dtype='int64', name='master_in')\n",
    "m1 = Embedding(n_masters, n_factors, input_length=1)(master_in)\n",
    "m2 = Flatten()(m1)\n",
    "order_in = Input(shape=(12,), dtype='float32', name='order_in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x =merge([m2, order_in], mode = 'concat')\n",
    "x = concatenate([m2, order_in])\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(200, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "master_in (InputLayer)           (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)          (None, 1, 50)         147400      master_in[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)              (None, 50)            0           embedding_9[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "order_in (InputLayer)            (None, 12)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)     (None, 62)            0           flatten_9[0][0]                  \n",
      "                                                                   order_in[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNor (None, 62)            248         concatenate_11[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)             (None, 62)            0           batch_normalization_31[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dense_31 (Dense)                 (None, 200)           12600       dropout_31[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNor (None, 200)           800         dense_31[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)             (None, 200)           0           batch_normalization_32[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dense_32 (Dense)                 (None, 100)           20100       dropout_32[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNor (None, 100)           400         dense_32[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)             (None, 100)           0           batch_normalization_33[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dense_33 (Dense)                 (None, 1)             101         dropout_33[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 181,649\n",
      "Trainable params: 180,925\n",
      "Non-trainable params: 724\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([master_in, order_in], x)\n",
    "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63183 samples, validate on 29999 samples\n",
      "Epoch 1/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.3135 - acc: 0.5214 - val_loss: 0.6807 - val_acc: 0.5894\n",
      "Epoch 2/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2803 - acc: 0.5503 - val_loss: 0.6620 - val_acc: 0.6608\n",
      "Epoch 3/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2751 - acc: 0.5669 - val_loss: 0.6372 - val_acc: 0.7131\n",
      "Epoch 4/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2713 - acc: 0.5841 - val_loss: 0.6364 - val_acc: 0.6936\n",
      "Epoch 5/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2667 - acc: 0.5986 - val_loss: 0.6015 - val_acc: 0.7263\n",
      "Epoch 6/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2633 - acc: 0.6064 - val_loss: 0.5935 - val_acc: 0.7120\n",
      "Epoch 7/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2590 - acc: 0.6212 - val_loss: 0.5782 - val_acc: 0.7229\n",
      "Epoch 8/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2550 - acc: 0.6363 - val_loss: 0.5806 - val_acc: 0.7054\n",
      "Epoch 9/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2512 - acc: 0.6495 - val_loss: 0.5659 - val_acc: 0.7190\n",
      "Epoch 10/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2486 - acc: 0.6544 - val_loss: 0.5543 - val_acc: 0.7288\n",
      "Epoch 11/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2464 - acc: 0.6628 - val_loss: 0.5620 - val_acc: 0.7141\n",
      "Epoch 12/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2445 - acc: 0.6654 - val_loss: 0.5513 - val_acc: 0.7241\n",
      "Epoch 13/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2415 - acc: 0.6711 - val_loss: 0.5468 - val_acc: 0.7266\n",
      "Epoch 14/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2400 - acc: 0.6751 - val_loss: 0.5517 - val_acc: 0.7166\n",
      "Epoch 15/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2394 - acc: 0.6790 - val_loss: 0.5547 - val_acc: 0.7109\n",
      "Epoch 16/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2385 - acc: 0.6787 - val_loss: 0.5511 - val_acc: 0.7135\n",
      "Epoch 17/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2364 - acc: 0.6835 - val_loss: 0.5459 - val_acc: 0.7157\n",
      "Epoch 18/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2361 - acc: 0.6847 - val_loss: 0.5450 - val_acc: 0.7141\n",
      "Epoch 19/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2350 - acc: 0.6855 - val_loss: 0.5526 - val_acc: 0.7028\n",
      "Epoch 20/1000\n",
      "63183/63183 [==============================] - 4s - loss: 0.2340 - acc: 0.6820 - val_loss: 0.5462 - val_acc: 0.7105\n",
      "Epoch 21/1000\n",
      "63183/63183 [==============================] - 5s - loss: 0.2338 - acc: 0.6861 - val_loss: 0.5390 - val_acc: 0.7179\n",
      "Epoch 22/1000\n",
      "63183/63183 [==============================] - 6s - loss: 0.2334 - acc: 0.6874 - val_loss: 0.5431 - val_acc: 0.7128\n",
      "Epoch 23/1000\n",
      "63183/63183 [==============================] - 4s - loss: 0.2324 - acc: 0.6847 - val_loss: 0.5372 - val_acc: 0.7172\n",
      "Epoch 24/1000\n",
      "63183/63183 [==============================] - 4s - loss: 0.2320 - acc: 0.6879 - val_loss: 0.5428 - val_acc: 0.7103\n",
      "Epoch 25/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2318 - acc: 0.6870 - val_loss: 0.5460 - val_acc: 0.7058\n",
      "Epoch 26/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2314 - acc: 0.6888 - val_loss: 0.5415 - val_acc: 0.7109\n",
      "Epoch 27/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2308 - acc: 0.6898 - val_loss: 0.5477 - val_acc: 0.7014\n",
      "Epoch 28/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2303 - acc: 0.6888 - val_loss: 0.5541 - val_acc: 0.6951\n",
      "Epoch 29/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2305 - acc: 0.6857 - val_loss: 0.5512 - val_acc: 0.6991\n",
      "Epoch 30/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2290 - acc: 0.6858 - val_loss: 0.5469 - val_acc: 0.7043\n",
      "Epoch 31/1000\n",
      "63183/63183 [==============================] - 3s - loss: 0.2297 - acc: 0.6888 - val_loss: 0.5381 - val_acc: 0.7124\n",
      "Epoch 32/1000\n",
      "61952/63183 [============================>.] - ETA: 0s - loss: 0.2288 - acc: 0.6892\n",
      "Epoch 00031: reducing learning rate to 0.030000000447034835.\n",
      "63183/63183 [==============================] - 3s - loss: 0.2289 - acc: 0.6889 - val_loss: 0.5454 - val_acc: 0.7044\n",
      "Epoch 00031: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x130a61f28>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = {1: 1.0, 0: y[y == 1].size / y[y == 0].size}\n",
    "\n",
    "model.fit([trn_X_new, trn_X2], trn_y, batch_size = 512, epochs=1000,\n",
    "          validation_data=([val_X_new, val_X2], val_y),\n",
    "          class_weight = class_weight,\n",
    "          callbacks = [EarlyStopping(monitor='val_loss', patience=30, verbose=1, min_delta=1e-4, mode='max'),\n",
    "                       #ReduceLROnPlateau(monitor='val_acc', factor=0.3, patience=5, verbose=1, epsilon=1e-4, mode='max')\n",
    "                        CSVLogger('data/learning_log.csv', separator=',', append=False),\n",
    "                        ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=8, min_lr=0.00001, verbose = 1)\n",
    "                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.753149765502\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([tst_X_new, tst_X2])\n",
    "print(roc_auc_score(tst_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('data/model_01.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred2 = y_pred.reshape((20000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "group_names = ['0-10', '10-20', '20-30', '30-40', '40-50', '50-60', '60-70', '70-80', '80-90', '90-100']\n",
    "\n",
    "categories = pd.cut(y_pred2, bins, labels=group_names)\n",
    "\n",
    "df = pd.DataFrame(columns=['y_true', 'y_pred', 'bin'])\n",
    "df['y_true'] = tst_y\n",
    "df['y_pred'] = y_pred2\n",
    "df['bin'] = categories\n",
    "\n",
    "df.to_csv('bins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_masters = X.nunique()\n",
    "n_factors = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model = Sequential([\n",
    "    Embedding(n_masters, n_factors, input_length=1),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.001), metrics=['accuracy'])\n",
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model.fit(X_new['master_idx'], y, batch_size=256, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
